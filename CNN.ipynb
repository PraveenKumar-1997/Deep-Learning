{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#Convolution \n",
    "classifier.add(Convolution2D(32,3,3, \n",
    "               input_shape = (64, 64, 3), \n",
    "               activation = 'relu')\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Adding second conv layer  (to the first pooled feature maps)\n",
    "classifier.add(Convolution2D(64,3,3, \n",
    "               activation = 'relu')\n",
    "              )\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('D:\\\\Machine-Learning-A-Z-New\\\\Machine Learning A-Z New\\\\Part 8 - Deep Learning\\\\Section 40 - Convolutional Neural Networks (CNN)\\\\dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting CNN to the images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                    shear_range = 0.2,\n",
    "                                    zoom_range = 0.2,\n",
    "                                    horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator( rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('D:\\\\Machine-Learning-A-Z-New\\\\Machine Learning A-Z New\\\\Part 8 - Deep Learning\\\\Section 40 - Convolutional Neural Networks (CNN)\\\\dataset\\\\training_set', \n",
    "                                                target_size = (64, 64),\n",
    "                                                batch_size = 32,\n",
    "                                                class_mode = 'binary')\n",
    "test_set = test_datagen.flow_from_directory('D:\\\\Machine-Learning-A-Z-New\\\\Machine Learning A-Z New\\\\Part 8 - Deep Learning\\\\Section 40 - Convolutional Neural Networks (CNN)\\\\dataset\\\\test_set',\n",
    "                                                target_size = (64, 64),\n",
    "                                                batch_size = 32,\n",
    "                                                class_mode = 'binary')\n",
    "classifier.fit_generator(training_set,\n",
    "                        samples_per_epoch = 8000,  # $ of train set images\n",
    "                        nb_epoch = 25,\n",
    "                        validation_data = test_set,\n",
    "                        nb_val_samples = 2000)        # $ of test set images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Challenge - Get the gold medal\n",
    "Homework Instruction\n",
    "\n",
    "\n",
    "\n",
    "Evaluation was already made during the training with the validation set, therefore k-Fold Cross Validation is not needed.\n",
    "\n",
    "Then the techniques to improve and tune a CNN model are the same as for ANNs. So here is the challenge:\n",
    "\n",
    "Apply the techniques you've learnt and use your architect power to make a CNN that will give you the gold medal:\n",
    "\n",
    "Bronze medal: Test set accuracy between 80% and 85%\n",
    "\n",
    "Silver medal: Test set accuracy between 85% and 90%\n",
    "\n",
    "Gold medal: Test set accuracy over 90%!!\n",
    "\n",
    "Rules:\n",
    "\n",
    "- Use the same training set\n",
    "\n",
    "- Dropout allowed\n",
    "\n",
    "- Customized SGD allowed\n",
    "\n",
    "- Specific seeds not allowed\n",
    "\n",
    "Tips will be provided soon.\n",
    "\n",
    "\n",
    "\n",
    "Enjoy Deep Learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.contrib.keras.api.keras.layers import Dropout\n",
    "# from tensorflow.contrib.keras.api.keras.models import Sequential\n",
    "# from tensorflow.contrib.keras.api.keras.layers import Conv2D\n",
    "# from tensorflow.contrib.keras.api.keras.layers import MaxPooling2D\n",
    "# from tensorflow.contrib.keras.api.keras.layers import Flatten\n",
    "# from tensorflow.contrib.keras.api.keras.layers import Dense\n",
    "# from tensorflow.contrib.keras.api.keras.callbacks import Callback\n",
    "# from tensorflow.contrib.keras.api.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.contrib.keras import backend\n",
    "# import os\n",
    " \n",
    " \n",
    "# class LossHistory(Callback):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.epoch_id = 0\n",
    "#         self.losses = ''\n",
    " \n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         self.losses += \"Epoch {}: accuracy -> {:.4f}, val_accuracy -> {:.4f}\\n\"\\\n",
    "#             .format(str(self.epoch_id), logs.get('acc'), logs.get('val_acc'))\n",
    "#         self.epoch_id += 1\n",
    " \n",
    "#     def on_train_begin(self, logs={}):\n",
    "#         self.losses += 'Training begins...\\n'\n",
    " \n",
    "# script_dir = os.path.dirname(__file__)\n",
    "# training_set_path = os.path.join(script_dir, '../dataset/training_set')\n",
    "# test_set_path = os.path.join(script_dir, '../dataset/test_set')\n",
    " \n",
    "# # Initialising the CNN\n",
    "# classifier = Sequential()\n",
    " \n",
    "# # Step 1 - Convolution\n",
    "# input_size = (128, 128)\n",
    "# classifier.add(Conv2D(32, (3, 3), input_shape=(*input_size, 3), activation='relu'))\n",
    " \n",
    "# # Step 2 - Pooling\n",
    "# classifier.add(MaxPooling2D(pool_size=(2, 2)))  # 2x2 is optimal\n",
    " \n",
    "# # Adding a second convolutional layer\n",
    "# classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "# # Adding a third convolutional layer\n",
    "# classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "# # Step 3 - Flattening\n",
    "# classifier.add(Flatten())\n",
    " \n",
    "# # Step 4 - Full connection\n",
    "# classifier.add(Dense(units=64, activation='relu'))\n",
    "# classifier.add(Dropout(0.5))\n",
    "# classifier.add(Dense(units=1, activation='sigmoid'))\n",
    " \n",
    "# # Compiling the CNN\n",
    "# classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "# # Part 2 - Fitting the CNN to the images\n",
    "# batch_size = 32\n",
    "# train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "#                                    shear_range=0.2,\n",
    "#                                    zoom_range=0.2,\n",
    "#                                    horizontal_flip=True)\n",
    " \n",
    "# test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    " \n",
    "# training_set = train_datagen.flow_from_directory(training_set_path,\n",
    "#                                                  target_size=input_size,\n",
    "#                                                  batch_size=batch_size,\n",
    "#                                                  class_mode='binary')\n",
    " \n",
    "# test_set = test_datagen.flow_from_directory(test_set_path,\n",
    "#                                             target_size=input_size,\n",
    "#                                             batch_size=batch_size,\n",
    "#                                             class_mode='binary')\n",
    " \n",
    "# # Create a loss history\n",
    "# history = LossHistory()\n",
    " \n",
    "# classifier.fit_generator(training_set,\n",
    "#                          steps_per_epoch=8000/batch_size,\n",
    "#                          epochs=90,\n",
    "#                          validation_data=test_set,\n",
    "#                          validation_steps=2000/batch_size,\n",
    "#                          workers=12,\n",
    "#                          max_q_size=100,\n",
    "#                          callbacks=[history])\n",
    " \n",
    " \n",
    "# # Save model\n",
    "# model_backup_path = os.path.join(script_dir, '../dataset/cat_or_dogs_model.h5')\n",
    "# classifier.save(model_backup_path)\n",
    "# print(\"Model saved to\", model_backup_path)\n",
    " \n",
    "# # Save loss history to file\n",
    "# loss_history_path = os.path.join(script_dir, '../loss_history.log')\n",
    "# myFile = open(loss_history_path, 'w+')\n",
    "# myFile.write(history.losses)\n",
    "# myFile.close()\n",
    " \n",
    "# backend.clear_session()\n",
    "# print(\"The model class indices are:\", training_set.class_indices)\n",
    "# loss: 0.1318 - acc: 0.9473 - val_loss: 0.3368 - val_acc: 0.9042\n",
    "\n",
    "# Tuatini"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
